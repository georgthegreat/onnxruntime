# Generated by devtools/yamaker.

LIBRARY()

LICENSE(
    Apache-2.0 AND
    BSD-3-Clause AND
    GPL-2.0-only AND
    LicenseRef-scancode-unknown-license-reference AND
    MIT
)

LICENSE_TEXTS(.yandex_meta/licenses.list.txt)

OWNER(
    g:cpp-contrib
    g:matrixnet
)

PEERDIR(
    build/platform/cuda
    contrib/libs/eigen
    contrib/libs/nsync
    contrib/libs/nvidia/cub
    contrib/libs/nvidia/cublas
    contrib/libs/nvidia/cudnn
    contrib/libs/nvidia/cufft
    contrib/libs/nvidia/thrust
    contrib/libs/onnx
    contrib/restricted/abseil-cpp/absl/base
    contrib/restricted/abseil-cpp/absl/container
    contrib/restricted/abseil-cpp/absl/debugging
    contrib/restricted/abseil-cpp/absl/hash
    contrib/restricted/abseil-cpp/absl/numeric
    contrib/restricted/abseil-cpp/absl/profiling
    contrib/restricted/abseil-cpp/absl/strings
    contrib/restricted/abseil-cpp/absl/synchronization
    contrib/restricted/abseil-cpp/absl/time
    contrib/restricted/abseil-cpp/absl/types
    contrib/restricted/boost/mp11
)

ADDINCL(
    contrib/libs/eigen
    contrib/libs/nsync/public
    contrib/libs/nvidia/cudnn
    contrib/libs/onnx_runtime
    contrib/libs/onnx_runtime/_deps/gsl-src/include
    contrib/libs/onnx_runtime/_deps/safeint-src
    contrib/libs/onnx_runtime/include/onnxruntime
    contrib/libs/onnx_runtime/include/onnxruntime/core/session
    contrib/libs/onnx_runtime/onnxruntime
)

NO_COMPILER_WARNINGS()

NO_UTIL()

CFLAGS(
    -DCPUINFO_SUPPORTED
    -DCPUINFO_SUPPORTED_PLATFORM=1
    -DEIGEN_MPL2_ONLY
    -DEIGEN_USE_THREADS
    -DENABLE_CPU_FP16_TRAINING_OPS
    -DNSYNC_ATOMIC_CPP11
    -DONNX_ML=1
    -DONNX_NAMESPACE=onnx
    -DONNX_USE_LITE_PROTO=1
    -DORT_ENABLE_STREAM
    -DPLATFORM_POSIX
    -DPROTOBUF_USE_DLLS
    -DUSE_CUDA=1
    -D__ONNX_NO_DOC_STRINGS
)

SRCDIR(contrib/libs/onnx_runtime/onnxruntime)

SRCS(
    GLOBAL core/providers/cuda/cuda_provider_factory.cc
    contrib_ops/cuda/activation/activations.cc
    contrib_ops/cuda/activation/activations_impl.cu
    contrib_ops/cuda/bert/add_bias_transpose.cu
    contrib_ops/cuda/bert/attention.cc
    contrib_ops/cuda/bert/attention_concat.cu
    contrib_ops/cuda/bert/attention_impl.cu
    contrib_ops/cuda/bert/attention_transpose.cu
    contrib_ops/cuda/bert/bert_padding.cu
    contrib_ops/cuda/bert/cutlass_fmha/fmha_sm50.cu
    contrib_ops/cuda/bert/cutlass_fmha/fmha_sm70.cu
    contrib_ops/cuda/bert/cutlass_fmha/fmha_sm75.cu
    contrib_ops/cuda/bert/cutlass_fmha/fmha_sm80.cu
    contrib_ops/cuda/bert/cutlass_fmha/memory_efficient_attention.cu
    contrib_ops/cuda/bert/decoder_attention.cc
    contrib_ops/cuda/bert/embed_layer_norm.cc
    contrib_ops/cuda/bert/embed_layer_norm_impl.cu
    contrib_ops/cuda/bert/fast_gelu.cc
    contrib_ops/cuda/bert/fast_gelu_impl.cu
    contrib_ops/cuda/bert/longformer_attention.cc
    contrib_ops/cuda/bert/longformer_attention_impl.cu
    contrib_ops/cuda/bert/longformer_attention_softmax.cu
    contrib_ops/cuda/bert/longformer_global_impl.cu
    contrib_ops/cuda/bert/multihead_attention.cc
    contrib_ops/cuda/bert/ngram_repeat_block.cc
    contrib_ops/cuda/bert/ngram_repeat_block_impl.cu
    contrib_ops/cuda/bert/relative_attn_bias.cc
    contrib_ops/cuda/bert/relative_attn_bias_impl.cu
    contrib_ops/cuda/bert/remove_padding.cc
    contrib_ops/cuda/bert/restore_padding.cc
    contrib_ops/cuda/bert/skip_layer_norm.cc
    contrib_ops/cuda/bert/skip_layer_norm_impl.cu
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_128_32_sm70.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_128_32_sm75.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_128_32_sm80.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_128_32_sm86.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_128_32_sm89.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_128_40_sm70.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_128_40_sm75.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_128_40_sm80.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_128_40_sm86.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_128_40_sm89.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_128_64_sm70.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_128_64_sm75.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_128_64_sm80.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_128_64_sm86.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_128_64_sm89.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_64_32_sm70.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_64_32_sm75.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_64_32_sm80.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_64_32_sm86.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_64_32_sm89.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_64_40_sm70.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_64_40_sm75.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_64_40_sm80.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_64_40_sm86.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_64_40_sm89.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_64_64_sm70.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_64_64_sm75.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_64_64_sm80.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_64_64_sm86.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/causal/fmha_v2_fp16_Causal_64_64_sm89.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/cross_attention/fmha_mhca_fp16_128_128_sm80.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/cross_attention/fmha_mhca_fp16_128_128_sm86.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/cross_attention/fmha_mhca_fp16_128_128_sm89.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/cross_attention/fmha_mhca_fp16_128_256_sm80.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/cross_attention/fmha_mhca_fp16_128_256_sm86.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/cross_attention/fmha_mhca_fp16_128_256_sm89.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/cross_attention/fmha_mhca_fp16_128_64_sm75.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/cross_attention/fmha_mhca_fp16_128_64_sm80.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/cross_attention/fmha_mhca_fp16_128_64_sm86.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/cross_attention/fmha_mhca_fp16_128_64_sm89.cubin.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/cudaDriverWrapper.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_128_16_S_16_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_128_16_S_16_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_128_16_S_16_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_128_16_S_32_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_128_16_S_32_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_128_16_S_32_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_128_16_S_40_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_128_16_S_40_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_128_16_S_40_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_128_16_S_64_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_128_16_S_64_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_128_16_S_64_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_128_32_S_128_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_128_32_S_128_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_128_32_S_128_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_128_32_S_80_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_128_32_S_80_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_128_32_S_80_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_16_S_160_sm75.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_16_S_160_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_16_S_160_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_16_S_160_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_16_S_256_sm75.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_16_S_256_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_16_S_256_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_16_S_256_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_32_S_128_sm75.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_32_S_128_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_32_S_128_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_32_S_128_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_32_S_16_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_32_S_16_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_32_S_16_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_32_S_32_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_32_S_32_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_32_S_32_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_32_S_40_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_32_S_40_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_32_S_40_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_32_S_64_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_32_S_64_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_32_S_64_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_32_S_80_sm75.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_32_S_80_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_32_S_80_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_32_S_80_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_64_S_16_sm75.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_64_S_32_sm75.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_64_S_40_sm75.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_64_S_64_sm70.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention/fmha_v2_flash_attention_fp16_64_64_S_64_sm75.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_128_sm70.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_128_sm75.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_128_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_128_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_128_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_144_sm70.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_144_sm75.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_144_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_144_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_144_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_160_sm70.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_160_sm75.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_160_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_160_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_160_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_256_sm70.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_256_sm75.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_256_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_256_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_256_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_32_sm70.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_32_sm75.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_32_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_32_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_32_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_40_sm70.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_40_sm75.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_40_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_40_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_40_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_64_sm70.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_64_sm75.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_64_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_64_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_64_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_80_sm70.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_80_sm75.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_80_sm80.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_80_sm86.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/flash_attention_causal/fmha_v2_flash_attention_fp16_Causal_0_80_sm89.cubin.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_128_32_kernel.sm75.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_128_32_kernel.sm80.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_128_64_kernel.sm70.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_128_64_kernel.sm75.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_128_64_kernel.sm80.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_128_64_kernel.sm86.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_192_32_kernel.sm75.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_192_32_kernel.sm80.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_192_64_kernel.sm75.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_192_64_kernel.sm80.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_256_32_kernel.sm75.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_256_32_kernel.sm80.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_256_64_kernel.sm70.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_256_64_kernel.sm75.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_256_64_kernel.sm80.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_256_64_kernel.sm86.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_32_32_kernel.sm75.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_32_32_kernel.sm80.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_32_64_kernel.sm75.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_32_64_kernel.sm80.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_384_32_kernel.sm75.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_384_32_kernel.sm80.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_384_64_kernel.sm70.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_384_64_kernel.sm75.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_384_64_kernel.sm80.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_384_64_kernel.sm86.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_64_32_kernel.sm75.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_64_32_kernel.sm80.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_64_64_kernel.sm70.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_64_64_kernel.sm75.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_64_64_kernel.sm80.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_64_64_kernel.sm86.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_96_32_kernel.sm75.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_96_32_kernel.sm80.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_96_64_kernel.sm70.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_96_64_kernel.sm75.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_96_64_kernel.sm80.cc
         contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/fused_multihead_attention_v2_fp16_96_64_kernel.sm86.cc
    contrib_ops/cuda/bert/tensorrt_fused_multihead_attention/mha_runner.cu
    contrib_ops/cuda/bert/transformer_common.cc
    contrib_ops/cuda/conv_transpose_with_dynamic_pads.cc
    contrib_ops/cuda/cuda_contrib_kernels.cc
    contrib_ops/cuda/diffusion/bias_split_gelu.cc
    contrib_ops/cuda/diffusion/bias_split_gelu_impl.cu
    contrib_ops/cuda/diffusion/group_norm.cc
    contrib_ops/cuda/diffusion/group_norm_impl.cu
    contrib_ops/cuda/diffusion/nhwc_conv.cc
    contrib_ops/cuda/fused_conv.cc
    contrib_ops/cuda/grid_sample.cc
    contrib_ops/cuda/grid_sample_impl.cu
    contrib_ops/cuda/inverse.cc
    contrib_ops/cuda/layer_norm.cc
    contrib_ops/cuda/math/bias_dropout.cc
    contrib_ops/cuda/math/bias_dropout_impl.cu
    contrib_ops/cuda/math/bias_softmax.cc
    contrib_ops/cuda/math/bias_softmax_impl.cu
    contrib_ops/cuda/math/binary_elementwise_ops.cc
    contrib_ops/cuda/math/binary_elementwise_ops_impl.cu
    contrib_ops/cuda/math/bitmask_dropout.cc
    contrib_ops/cuda/math/complex_mul.cc
    contrib_ops/cuda/math/complex_mul_impl.cu
    contrib_ops/cuda/math/fft_ops.cc
    contrib_ops/cuda/math/fft_ops_impl.cu
    contrib_ops/cuda/math/fused_matmul.cc
    contrib_ops/cuda/math/isfinite.cc
    contrib_ops/cuda/math/isfinite_impl.cu
    contrib_ops/cuda/quantization/attention_quantization.cc
    contrib_ops/cuda/quantization/attention_quantization_impl.cu
    contrib_ops/cuda/quantization/qordered_ops/qordered_attention.cc
    contrib_ops/cuda/quantization/qordered_ops/qordered_attention_impl.cu
    contrib_ops/cuda/quantization/qordered_ops/qordered_layer_norm.cc
    contrib_ops/cuda/quantization/qordered_ops/qordered_layer_norm_impl.cu
    contrib_ops/cuda/quantization/qordered_ops/qordered_longformer_attention.cc
    contrib_ops/cuda/quantization/qordered_ops/qordered_matmul.cc
    contrib_ops/cuda/quantization/qordered_ops/qordered_matmul_utils.cc
    contrib_ops/cuda/quantization/qordered_ops/qordered_qdq.cc
    contrib_ops/cuda/quantization/qordered_ops/qordered_qdq_impl.cu
    contrib_ops/cuda/quantization/qordered_ops/qordered_unary_ops.cc
    contrib_ops/cuda/quantization/qordered_ops/qordered_unary_ops_impl.cu
    contrib_ops/cuda/quantization/quantize_dequantize_linear.cc
    contrib_ops/cuda/tensor/crop.cc
    contrib_ops/cuda/tensor/crop_impl.cu
    contrib_ops/cuda/tensor/dynamicslice.cc
    contrib_ops/cuda/tensor/image_scaler.cc
    contrib_ops/cuda/tensor/image_scaler_impl.cu
    contrib_ops/cuda/tensor/trilu.cc
    contrib_ops/cuda/transformers/beam_search.cc
    contrib_ops/cuda/transformers/beam_search_topk.cu
    contrib_ops/cuda/transformers/dump_cuda_tensor.cc
    contrib_ops/cuda/transformers/generation_cuda_impl.cu
    contrib_ops/cuda/transformers/generation_device_helper.cc
    contrib_ops/cuda/transformers/greedy_search.cc
    contrib_ops/cuda/transformers/greedy_search_top_one.cu
    contrib_ops/cuda/transformers/sampling.cc
    core/providers/cuda/activation/activations.cc
    core/providers/cuda/activation/activations_impl.cu
    core/providers/cuda/controlflow/if.cc
    core/providers/cuda/controlflow/loop.cc
    core/providers/cuda/controlflow/scan.cc
    core/providers/cuda/cuda_allocator.cc
    core/providers/cuda/cuda_call.cc
    core/providers/cuda/cuda_check_memory.cc
    core/providers/cuda/cuda_common.cc
    core/providers/cuda/cuda_execution_provider.cc
    core/providers/cuda/cuda_execution_provider_info.cc
    core/providers/cuda/cuda_graph.cc
    core/providers/cuda/cuda_profiler.cc
    core/providers/cuda/cuda_stream_handle.cc
    core/providers/cuda/cuda_utils.cu
    core/providers/cuda/cudnn_common.cc
    core/providers/cuda/cupti_manager.cc
    core/providers/cuda/fpgeneric.cu
    core/providers/cuda/generator/constant_of_shape.cc
    core/providers/cuda/generator/random.cc
    core/providers/cuda/generator/random_impl.cu
    core/providers/cuda/generator/range.cc
    core/providers/cuda/generator/range_impl.cu
    core/providers/cuda/gpu_data_transfer.cc
    core/providers/cuda/integer_gemm.cc
    core/providers/cuda/math/binary_elementwise_ops.cc
    core/providers/cuda/math/binary_elementwise_ops_impl.cu
    core/providers/cuda/math/clip.cc
    core/providers/cuda/math/clip_impl.cu
    core/providers/cuda/math/cumsum.cc
    core/providers/cuda/math/cumsum_impl.cu
    core/providers/cuda/math/einsum.cc
    core/providers/cuda/math/einsum_utils/einsum_auxiliary_ops.cc
    core/providers/cuda/math/einsum_utils/einsum_auxiliary_ops_diagonal.cu
    core/providers/cuda/math/gemm.cc
    core/providers/cuda/math/matmul.cc
    core/providers/cuda/math/matmul_integer.cc
    core/providers/cuda/math/matmul_integer.cu
    core/providers/cuda/math/softmax.cc
    core/providers/cuda/math/softmax_common.cc
    core/providers/cuda/math/softmax_impl.cu
    core/providers/cuda/math/topk.cc
    core/providers/cuda/math/topk_impl_f16.cu
    core/providers/cuda/math/topk_impl_f32.cu
    core/providers/cuda/math/topk_impl_f64.cu
    core/providers/cuda/math/topk_impl_i32.cu
    core/providers/cuda/math/topk_impl_i64.cu
    core/providers/cuda/math/unary_elementwise_ops.cc
    core/providers/cuda/math/unary_elementwise_ops_impl.cu
    core/providers/cuda/math/variadic_elementwise_ops.cc
    core/providers/cuda/math/variadic_elementwise_ops_impl.cu
    core/providers/cuda/nn/batch_norm.cc
    core/providers/cuda/nn/conv.cc
    core/providers/cuda/nn/conv_transpose.cc
    core/providers/cuda/nn/dropout.cc
    core/providers/cuda/nn/dropout_impl.cu
    core/providers/cuda/nn/instance_norm.cc
    core/providers/cuda/nn/instance_norm_impl.cu
    core/providers/cuda/nn/layer_norm.cc
    core/providers/cuda/nn/layer_norm_impl.cu
    core/providers/cuda/nn/lrn.cc
    core/providers/cuda/nn/max_pool_with_index.cu
    core/providers/cuda/nn/pool.cc
    core/providers/cuda/nn/shrink.cc
    core/providers/cuda/nn/shrink_impl.cu
    core/providers/cuda/nvtx_profile.cc
    core/providers/cuda/object_detection/non_max_suppression.cc
    core/providers/cuda/object_detection/non_max_suppression_impl.cu
    core/providers/cuda/object_detection/roialign.cc
    core/providers/cuda/object_detection/roialign_impl.cu
    core/providers/cuda/reduction/reduction_functions.cc
    core/providers/cuda/reduction/reduction_functions.cu
    core/providers/cuda/reduction/reduction_ops.cc
    core/providers/cuda/rnn/cudnn_rnn_base.cc
    core/providers/cuda/rnn/gru.cc
    core/providers/cuda/rnn/lstm.cc
    core/providers/cuda/rnn/rnn.cc
    core/providers/cuda/rnn/rnn_impl.cu
    core/providers/cuda/tensor/cast_op.cc
    core/providers/cuda/tensor/compress.cc
    core/providers/cuda/tensor/compress_impl.cu
    core/providers/cuda/tensor/concat.cc
    core/providers/cuda/tensor/concat_impl.cu
    core/providers/cuda/tensor/expand.cc
    core/providers/cuda/tensor/expand_impl.cu
    core/providers/cuda/tensor/eye_like.cc
    core/providers/cuda/tensor/eye_like_impl.cu
    core/providers/cuda/tensor/flatten.cc
    core/providers/cuda/tensor/gather.cc
    core/providers/cuda/tensor/gather_elements.cc
    core/providers/cuda/tensor/gather_elements_impl.cu
    core/providers/cuda/tensor/gather_impl.cu
    core/providers/cuda/tensor/gather_nd.cc
    core/providers/cuda/tensor/gather_nd_impl.cu
    core/providers/cuda/tensor/identity_op.cc
    core/providers/cuda/tensor/nonzero_impl.cu
    core/providers/cuda/tensor/nonzero_op.cc
    core/providers/cuda/tensor/onehot.cc
    core/providers/cuda/tensor/onehot.cu
    core/providers/cuda/tensor/pad.cc
    core/providers/cuda/tensor/pad_impl.cu
    core/providers/cuda/tensor/quantize_linear.cc
    core/providers/cuda/tensor/quantize_linear.cu
    core/providers/cuda/tensor/reshape.cc
    core/providers/cuda/tensor/resize.cc
    core/providers/cuda/tensor/resize_impl.cu
    core/providers/cuda/tensor/reverse_sequence.cc
    core/providers/cuda/tensor/reverse_sequence_impl.cu
    core/providers/cuda/tensor/scatter_elements.cc
    core/providers/cuda/tensor/scatter_nd.cc
    core/providers/cuda/tensor/scatter_nd_impl.cu
    core/providers/cuda/tensor/sequence_op.cc
    core/providers/cuda/tensor/shape_op.cc
    core/providers/cuda/tensor/size.cc
    core/providers/cuda/tensor/slice.cc
    core/providers/cuda/tensor/slice_impl.cu
    core/providers/cuda/tensor/space_depth_ops.cc
    core/providers/cuda/tensor/split.cc
    core/providers/cuda/tensor/split_impl.cu
    core/providers/cuda/tensor/squeeze.cc
    core/providers/cuda/tensor/tile.cc
    core/providers/cuda/tensor/tile_impl.cu
    core/providers/cuda/tensor/transpose.cc
    core/providers/cuda/tensor/transpose_impl.cu
    core/providers/cuda/tensor/trilu.cc
    core/providers/cuda/tensor/trilu_impl.cu
    core/providers/cuda/tensor/unsqueeze.cc
    core/providers/cuda/tensor/upsample.cc
    core/providers/cuda/tensor/upsample_impl.cu
    core/providers/cuda/tensor/where.cc
    core/providers/cuda/tensor/where_impl.cu
    core/providers/cuda/test/beam_search_topk.cc
    core/providers/cuda/test/cuda_execution_provider_test.cc
    core/providers/cuda/test/greedy_search_top_one.cc
    core/providers/cuda/tunable/util.cc
    core/providers/shared_library/provider_bridge_cpu.cc
    core/providers/shared_library/provider_bridge_einsum.cc
    core/providers/shared_library/provider_bridge_unload.cc
    core/providers/shared_library/provider_ort_api_init.cc
)

END()
